result_path: ${hydra:runtime.output_dir}

dataset:
  name: ReDocRED
  path: data/redocred
  rel2id: ${dataset.path}/rel2id.json
  sets:
    train: ${dataset.path}/train_revised.json
    dev  : ${dataset.path}/dev_revised.json
    test : ${dataset.path}/test_revised.json
  num_class: 97
  max_seq_length: 1024
  cached_location: ${dataset.path}/cached.pkl

encoder:
  name: roberta-large
  transformer_type: roberta # roberta or bert
  lazy: True

trainer:
  epochs: 30
  batch_size: 4
  grad_accum_step: 1
  eval_freq: -1
  print_freq: 200
  max_grad_norm: -1
  model_save: ${result_path}/best.pt

  pretrain_lr: !!float 1e-5
  new_lr: !!float 8e-5
  warmup_ratio: 0.06
  optimizer_cfg:
    name: Adam
    kwargs:
      betas:
        - 0.9 # beta1
        - 0.98 # beta2
      eps: !!float 1e-9

tester:
  batch_size: 8

loss:
  temp: "this is loss"

model:
  temp: "this is model"
